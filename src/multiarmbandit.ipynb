{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7218352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c30d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the slot machines with probability of reward (all rewards are same)\n",
    "machines = np.array([0.2, 0.5, 0.6, 0.1])\n",
    "cumulative_rewards = np.zeros_like(machines)\n",
    "picks = np.zeros_like(machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54c3d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate reward based on probability and machine choice\n",
    "def gen_reward(machines, idx):\n",
    "    rewards = np.zeros_like(machines)\n",
    "    picks = np.zeros_like(machines)\n",
    "    if np.random.uniform(0,1,1) < machines[idx]:\n",
    "        rewards[idx] = 1\n",
    "    picks[idx] = 1\n",
    "    print(f\"Choice {picks}\")\n",
    "    return rewards, picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d0aba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_rewards(new_reward, prev_cumulative_rewards):\n",
    "    return prev_cumulative_rewards + new_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "75dfe2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_policy(policy, machines, cumulative_rewards, old_picks, **kwargs):\n",
    "    new_reward, pick = policy(machines, cumulative_rewards, old_picks, **kwargs)\n",
    "    cumulative_rewards = accumulate_rewards(new_reward, cumulative_rewards)\n",
    "    cumulative_picks = old_picks + pick\n",
    "    return cumulative_rewards, cumulative_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb8d255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(machines, cumulative_rewards, picks, **kwargs):\n",
    "    means = cumulative_rewards / picks\n",
    "    max_mean = np.max(means)\n",
    "    max_mean_idx = np.argmax(means)\n",
    "\n",
    "    return gen_reward(machines, max_mean_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "691b9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(machines, cumulative_rewards, picks, **kwargs):\n",
    "    epsilon = kwargs.get(\"epsilon\", 0.1)\n",
    "    exploit = np.random.uniform(0,1,1) < 1-epsilon\n",
    "    if exploit:\n",
    "        print(\"Exploiting\")\n",
    "        return greedy_policy(machines, cumulative_rewards, picks)\n",
    "    else:\n",
    "        print(\"Exploring\")\n",
    "        idx = np.random.randint(0,machines.shape[0],1)\n",
    "        pick = np.zeros_like(machines)\n",
    "        pick[idx] = 1\n",
    "        return gen_reward(machines, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d23b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decaying_epsilon_greedy_policy(machines, cumulative_rewards, picks, **kwargs):\n",
    "    iters=kwargs.get(\"iters\", 0)\n",
    "    eps_0 = kwargs.get(\"eps_0\", 0.1)\n",
    "    epsilon = eps_0 * np.exp(-iters)\n",
    "    print(f\"Epsilon {epsilon}\")\n",
    "    return epsilon_greedy_policy(machines, cumulative_rewards, picks, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "91d39b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_confidence_bound_policy(machines, cumulative_rewards, picks, **kwargs):\n",
    "    steps = kwargs.get(\"iters\", 0)\n",
    "    confidence = kwargs.get(\"c\", 0.1)\n",
    "    mean = cumulative_rewards / picks\n",
    "\n",
    "    mean_mod = mean + confidence * np.sqrt((1/np.log(steps))*picks)\n",
    "\n",
    "    idx = np.argmax(mean_mod)\n",
    "    return gen_reward(machines, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfe96747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice [1. 0. 0. 0.]\n",
      "Cumulative rewards: [0. 0. 0. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 1. 0. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 1. 1. 0.]\n",
      "Choice [0. 0. 0. 1.]\n",
      "Cumulative rewards: [0. 1. 1. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 2. 1. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 3. 1. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 3. 1. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 3. 2. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 3. 3. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 3. 3. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 4. 3. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 4. 3. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 4. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 4. 0.]\n",
      "Choice [0. 1. 0. 0.]\n",
      "Cumulative rewards: [0. 4. 4. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 5. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 5. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 5. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 6. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 7. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 7. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 8. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 8. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 9. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 9. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [0. 4. 9. 0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 10.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 11.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 12.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 13.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 14.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 14.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 15.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 16.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 16.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 17.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 17.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 18.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 19.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 20.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 20.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 21.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 22.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 22.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 22.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 22.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 22.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 23.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 23.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 24.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 25.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 26.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 26.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 27.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 27.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 28.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 29.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 30.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 30.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 31.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 31.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 32.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 32.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 32.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 33.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 34.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 34.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 35.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 36.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 37.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 38.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 39.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 39.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 39.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 39.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 39.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 40.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 40.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 41.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 42.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 42.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 42.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 43.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 43.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 44.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 44.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 45.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 46.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 47.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 48.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 48.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 49.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 49.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 49.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 50.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 51.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 51.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 52.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 53.  0.]\n",
      "Choice [0. 0. 1. 0.]\n",
      "Cumulative rewards: [ 0.  4. 54.  0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TFran\\AppData\\Local\\Temp\\ipykernel_45060\\2847785492.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  mean = cumulative_rewards / picks\n",
      "C:\\Users\\TFran\\AppData\\Local\\Temp\\ipykernel_45060\\2847785492.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  mean_mod = mean + confidence * np.sqrt((1/np.log(steps))*picks)\n",
      "C:\\Users\\TFran\\AppData\\Local\\Temp\\ipykernel_45060\\2847785492.py:6: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  mean_mod = mean + confidence * np.sqrt((1/np.log(steps))*picks)\n",
      "C:\\Users\\TFran\\AppData\\Local\\Temp\\ipykernel_45060\\2847785492.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  mean_mod = mean + confidence * np.sqrt((1/np.log(steps))*picks)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    cumulative_rewards, picks = apply_policy(upper_confidence_bound_policy, machines, cumulative_rewards, picks, iters=i, c=0.1)\n",
    "    print(f\"Cumulative rewards: {cumulative_rewards}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
